// This file was generated by lezer-generator. You probably shouldn't edit it.
import {LRParser} from "@lezer/lr"
import {noteContent} from "./external-tokens.js"
export const parser = LRParser.deserialize({
  version: 14,
  states: "!jQQOPOOOVOPO'#C`O[OQO'#C_OOOO'#Cc'#CcQQOPOOOaOPO,58zOOOO,58y,58yOOOO-E6a-E6aOfOPO1G.fOOOQ7+$Q7+$QOnOPO7+$QOOOQ<<Gl<<Gl",
  stateData: "s~OXPO~OYTO~OPUO~OTWO~OUYOXXO~OXZO~O",
  goto: "gWPPPX]PPaTROSTQOSQSORVS",
  nodeNames: "âš  NoteContent Document Note NoteDelimiter NoteLanguage Auto",
  maxTerm: 10,
  skippedNodes: [0],
  repeatNodeCount: 1,
  tokenData: "/p~RcYZ!^}!O!c#V#W!n#W#X$[#X#Y$}#Z#[&Y#[#]&{#^#_'_#_#`(u#`#a)_#a#b)z#d#e*y#f#g,e#g#h,t#h#i.S#j#k/R#l#m'R#m#n/X%&x%&y/_~!cOX~~!fP#T#U!i~!nOU~~!qR#`#a!z#d#e#o#g#h#u~!}P#c#d#Q~#TP#^#_#W~#ZP#i#j#^~#aP#f#g#d~#gP#X#Y#j~#oOT~~#rP#d#e#j~#xQ#[#]$O#g#h#j~$RP#T#U$U~$XP#f#g#o~$_Q#T#U$e#]#^$q~$hP#f#g$k~$nP#h#i#j~$tP#Y#Z$w~$zP#Y#Z#j~%QQ#`#a%W#f#g%p~%ZP#]#^%^~%aP#l#m%d~%gP#]#^%j~%mP#f#g#j~%sP#`#a%v~%yP#T#U%|~&PP#b#c&S~&VP#Z#[#j~&]Q#c#d%p#f#g&c~&fP#c#d&i~&lP#c#d&o~&rP#j#k&u~&xP#m#n#j~'OP#h#i'R~'UP#a#b'X~'[P#`#a#j~'bQ#T#U'h#g#h(f~'kP#j#k'n~'qP#T#U't~'yPT~#g#h'|~(PP#V#W(S~(VP#f#g(Y~(]P#]#^(`~(cP#d#e$k~(iQ#c#d(o#l#m#j~(rP#b#c#j~(xP#c#d({~)OP#h#i)R~)UP#`#a)X~)[P#]#^(o~)bQ#X#Y)h#i#j)t~)kP#n#o)n~)qP#X#Y%j~)wP#T#U#j~)}P#T#U*Q~*TQ#f#g*Z#h#i*s~*^P#_#`*a~*dP#W#X*g~*jP#c#d*m~*pP#k#l(o~*vP#[#]#j~*|R#[#]#o#c#d+V#m#n,R~+YP#k#l+]~+`P#X#Y+c~+fP#f#g+i~+lP#g#h+o~+rP#[#]+u~+xP#X#Y+{~,OP#`#a'X~,UP#h#i,X~,[P#[#],_~,bP#c#d(o~,hP#i#j,k~,nQ#U#V&u#g#h$k~,wT#V#W-W#[#]+u#e#f'X#j#k-d#k#l-v~-ZP#T#U-^~-aP#`#a)t~-gP#X#Y-j~-mP#`#a-p~-sP#h#i#d~-yP#]#^-|~.PP#Y#Z$k~.VS#X#Y.c#c#d'R#g#h.i#m#n.o~.fP#l#m$k~.lP#l#m#j~.rP#d#e.u~.xP#X#Y.{~/OP#g#h'|~/UP#i#j#d~/[P#T#U'R~/bP%&x%&y/e~/hP%&x%&y/k~/pOY~",
  tokenizers: [0, noteContent],
  topRules: {"Document":[0,2]},
  tokenPrec: 0
})
